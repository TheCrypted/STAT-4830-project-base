{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e25156-ab19-437e-be80-a26a47a7b012",
   "metadata": {},
   "source": [
    "## Graph Neural Network Model for Route Optimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fefc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install osmnx\n",
    "!pip install pandas numpy osmnx geopandas shapely matplotlib scikit-learn pathlib gymnasium torch torch_geometric torch_sparse torch_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5857bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import warnings\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GINEConv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.nn import Linear, ReLU, Dropout, LayerNorm, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ac816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\"invalid value encountered in cast\", category=RuntimeWarning)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# === 1) Load & Clean EV CSVs ===\n",
    "temp_cols = [\n",
    "    'VehId','Trip','Timestamp(ms)',\n",
    "    'Latitude[deg]','Longitude[deg]',\n",
    "    'Vehicle Speed[km/h]','MAF[g/sec]',\n",
    "    'Engine RPM[RPM]','Absolute Load[%]',\n",
    "    'Speed Limit[km/h]'\n",
    "]\n",
    "dtypes = {'VehId':'int32','Trip':'int32'}\n",
    "chunksize = 200_000\n",
    "\n",
    "lat_mins, lat_maxs, lon_mins, lon_maxs = [], [], [], []\n",
    "_cleaned_frames = []\n",
    "\n",
    "def load_ev_data(path):\n",
    "    for chunk in pd.read_csv(\n",
    "        path,\n",
    "        usecols=temp_cols,\n",
    "        dtype=dtypes,\n",
    "        chunksize=chunksize,\n",
    "        low_memory=False,\n",
    "        on_bad_lines='warn'\n",
    "    ):\n",
    "        # Convert to numeric, fillna\n",
    "        for c in temp_cols[2:]:\n",
    "            if c in chunk:\n",
    "                num = pd.to_numeric(chunk[c], errors='coerce').fillna(0)\n",
    "                chunk[c] = num.astype('float32') if c!='Timestamp(ms)' else num.astype('int64')\n",
    "        # Drop zeros lat/lon\n",
    "        chunk = chunk[(chunk['Latitude[deg]']!=0)&(chunk['Longitude[deg]']!=0)]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "        lat_mins.append(chunk['Latitude[deg]'].min())\n",
    "        lat_maxs.append(chunk['Latitude[deg]'].max())\n",
    "        lon_mins.append(chunk['Longitude[deg]'].min())\n",
    "        lon_maxs.append(chunk['Longitude[deg]'].max())\n",
    "        _cleaned_frames.append(chunk.sort_values(['VehId','Trip','Timestamp(ms)']))\n",
    "\n",
    "file_paths = glob.glob('./eVED/*.csv')\n",
    "if not file_paths:\n",
    "    raise FileNotFoundError(\"No CSV files found in ./eVED/\")\n",
    "for p in file_paths:\n",
    "    load_ev_data(p)\n",
    "\n",
    "ev_df = pd.concat(_cleaned_frames, ignore_index=True)\n",
    "print(f\"Loaded EV data: {len(ev_df)} rows\")\n",
    "\n",
    "LAT_MIN, LAT_MAX = min(lat_mins), max(lat_maxs)\n",
    "LNG_MIN, LNG_MAX = min(lon_mins), max(lon_maxs)\n",
    "\n",
    "def normalize_coords(lat, lon):\n",
    "    nl = (lat - LAT_MIN)/(LAT_MAX - LAT_MIN) if LAT_MAX!=LAT_MIN else 0\n",
    "    ml = (lon - LNG_MIN)/(LNG_MAX - LNG_MIN) if LNG_MAX!=LNG_MIN else 0\n",
    "    return np.clip(nl,0,1), np.clip(ml,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8988099",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_lat, center_lon = (LAT_MIN+LAT_MAX)/2, (LNG_MIN+LNG_MAX)/2\n",
    "print(\"Downloading OSMnx graph…\")\n",
    "G_nx = ox.graph_from_point((center_lat, center_lon), dist=30000, network_type='drive')\n",
    "\n",
    "node_id_map = {nid:i for i,nid in enumerate(G_nx.nodes())}\n",
    "idx2osm = {i:nid for nid,i in node_id_map.items()}\n",
    "\n",
    "# Node features: normalized coords\n",
    "node_feats = []\n",
    "for nid, data in G_nx.nodes(data=True):\n",
    "    nl, ml = normalize_coords(data['y'], data['x'])\n",
    "    node_feats.append([nl, ml])\n",
    "x = torch.tensor(node_feats, dtype=torch.float)\n",
    "\n",
    "# Edge features + index\n",
    "e_u, e_v, edge_feats = [], [], []\n",
    "lengths, speeds = [], []\n",
    "for u, v, data in G_nx.edges(data=True):\n",
    "    lengths.append(data.get('length', 0.0))\n",
    "    ms = data.get('maxspeed', 0)\n",
    "    if isinstance(ms, list): ms = ms[0]\n",
    "    try:\n",
    "        speeds.append(float(str(ms).split()[0]))\n",
    "    except:\n",
    "        speeds.append(0.0)\n",
    "\n",
    "max_len = max(lengths) or 1.0\n",
    "MAX_SP = 130.0\n",
    "\n",
    "for (u, v), length, speed in zip(G_nx.edges(), lengths, speeds):\n",
    "    ui, vi = node_id_map[u], node_id_map[v]\n",
    "    e_u.append(ui); e_v.append(vi)\n",
    "    nl = length / max_len\n",
    "    ns = np.clip(speed / MAX_SP, 0, 1)\n",
    "    edge_feats.append([nl, ns])\n",
    "\n",
    "edge_index = torch.tensor([e_u, e_v], dtype=torch.long)\n",
    "edge_attr  = torch.tensor(edge_feats, dtype=torch.float)\n",
    "graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr).to(DEVICE)\n",
    "print(graph)\n",
    "\n",
    "# Precompute quick lookup from (osm_u,osm_v) → edge_idx\n",
    "osm_edge_to_idx = {\n",
    "    (idx2osm[u], idx2osm[v]): i\n",
    "    for i, (u, v) in enumerate(zip(edge_index[0].tolist(), edge_index[1].tolist()))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba44b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_df['node_osm'] = ox.nearest_nodes(\n",
    "    G_nx,\n",
    "    X=ev_df['Longitude[deg]'],\n",
    "    Y=ev_df['Latitude[deg]']\n",
    ")\n",
    "ev_df['node_idx'] = ev_df['node_osm'].map(node_id_map)\n",
    "ev_df.dropna(subset=['node_idx'], inplace=True)\n",
    "ev_df['node_idx'] = ev_df['node_idx'].astype(int)\n",
    "ev_df.sort_values(['VehId','Trip','Timestamp(ms)'], inplace=True)\n",
    "\n",
    "# Compute per-step durations & energy\n",
    "ev_df['duration_s'] = ev_df.groupby(['VehId','Trip'])['Timestamp(ms)']\\\n",
    "                       .diff().fillna(0) / 1000\n",
    "ev_df['step_energy'] = ev_df['MAF[g/sec]'] * ev_df['duration_s']\n",
    "\n",
    "# Collect trips with start, end, true_energy\n",
    "trips = []\n",
    "for _, grp in ev_df.groupby(['VehId','Trip']):\n",
    "    if len(grp) < 2:\n",
    "        continue\n",
    "    s = int(grp.iloc[0].node_idx)\n",
    "    d = int(grp.iloc[-1].node_idx)\n",
    "    E = grp.step_energy.sum()\n",
    "    if s != d and E > 0:\n",
    "        trips.append({'source': s, 'destination': d, 'true_energy': E})\n",
    "\n",
    "trips_df = pd.DataFrame(trips)\n",
    "print(f\"Processed {len(trips_df)} trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathTripDataset(Dataset):\n",
    "    def __init__(self, trip_df, osm_graph, osm_to_idx, edge_lookup):\n",
    "        self.trips = trip_df.reset_index(drop=True)\n",
    "        self.G_nx = osm_graph\n",
    "        self.idx2osm = idx2osm\n",
    "        self.edge_lookup = edge_lookup\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trips)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        r = self.trips.iloc[i]\n",
    "        src_idx = int(r.source)\n",
    "        dst_idx = int(r.destination)\n",
    "        os_src = self.idx2osm[src_idx]\n",
    "        os_dst = self.idx2osm[dst_idx]\n",
    "\n",
    "        # shortest path of osm IDs\n",
    "        try:\n",
    "            path_nodes = nx.shortest_path(\n",
    "                self.G_nx, os_src, os_dst, weight='length'\n",
    "            )\n",
    "        except (nx.NetworkXNoPath, nx.NodeNotFound):\n",
    "            path_nodes = []\n",
    "\n",
    "        # map successive node pairs to edge indices\n",
    "        idxs = []\n",
    "        for u_osm, v_osm in zip(path_nodes[:-1], path_nodes[1:]):\n",
    "            ei = self.edge_lookup.get((u_osm, v_osm))\n",
    "            if ei is not None:\n",
    "                idxs.append(ei)\n",
    "\n",
    "        edge_idxs = torch.tensor(idxs, dtype=torch.long)\n",
    "        energy_log = torch.tensor(np.log1p(r.true_energy), dtype=torch.float32)\n",
    "        return edge_idxs, energy_log\n",
    "\n",
    "def collate_paths(batch):\n",
    "    paths, energies = zip(*batch)\n",
    "    return list(paths), torch.stack(energies)\n",
    "\n",
    "# Splits\n",
    "train_df, val_df = train_test_split(trips_df, test_size=0.15, random_state=42)\n",
    "train_ds = PathTripDataset(train_df, G_nx, node_id_map, osm_edge_to_idx)\n",
    "val_ds   = PathTripDataset(val_df,   G_nx, node_id_map, osm_edge_to_idx)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=16, shuffle=True, collate_fn=collate_paths\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=32, shuffle=False, collate_fn=collate_paths\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dda197",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNPathEnergyPredictor(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hid=128, rnn_hid=128, nlayers=4, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.node_emb = Linear(node_dim, hid)\n",
    "        self.edge_emb = Linear(edge_dim, hid)\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        for _ in range(nlayers):\n",
    "            mlp = nn.Sequential(Linear(hid, hid), ReLU(), Linear(hid, hid))\n",
    "            self.convs.append(GINEConv(mlp, edge_dim=hid))\n",
    "            self.norms.append(LayerNorm(hid))\n",
    "\n",
    "        self.rnn = GRU(input_size=3*hid, hidden_size=rnn_hid, batch_first=True)\n",
    "        self.decoder = nn.Sequential(\n",
    "            Linear(rnn_hid, hid),\n",
    "            ReLU(),\n",
    "            Dropout(drop),\n",
    "            Linear(hid, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, graph, path_list):\n",
    "        x = self.node_emb(graph.x)\n",
    "        ea = self.edge_emb(graph.edge_attr)\n",
    "        # GINE layers\n",
    "        for conv, norm in zip(self.convs, self.norms):\n",
    "            res = x\n",
    "            x = conv(x, graph.edge_index, ea)\n",
    "            x = norm(x)\n",
    "            x = F.relu(x) + res\n",
    "        emb = x\n",
    "\n",
    "        # build per-path sequences of [src_emb | edge_emb | dst_emb]\n",
    "        seqs = []\n",
    "        for eidx in path_list:\n",
    "            src_nodes = graph.edge_index[0, eidx]\n",
    "            dst_nodes = graph.edge_index[1, eidx]\n",
    "            seq = torch.cat([emb[src_nodes], ea[eidx], emb[dst_nodes]], dim=1)\n",
    "            seqs.append(seq)\n",
    "\n",
    "        # pack & GRU\n",
    "        lengths = [s.size(0) for s in seqs]\n",
    "        padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            padded, lengths, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, h = self.rnn(packed)\n",
    "        out = self.decoder(h.squeeze(0)).squeeze(1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNNPathEnergyPredictor(\n",
    "    node_dim=graph.x.shape[1],\n",
    "    edge_dim=graph.edge_attr.shape[1]\n",
    ").to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "best_val = float('inf')\n",
    "for epoch in range(1, 31):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for paths, energies in tqdm(train_loader, desc=f\"Epoch {epoch} [train]\"):\n",
    "        opt.zero_grad()\n",
    "        preds = model(graph, [p.to(DEVICE) for p in paths])\n",
    "        loss = loss_fn(preds, energies.to(DEVICE))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for paths, energies in tqdm(val_loader, desc=f\"Epoch {epoch} [val]\"):\n",
    "            preds = model(graph, [p.to(DEVICE) for p in paths])\n",
    "            val_loss += loss_fn(preds, energies.to(DEVICE)).item()\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train {train_loss:.4f} | val {val_loss:.4f} | {time.time()-t0:.1f}s\")\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        torch.save(model.state_dict(), './best_path_energy_predictor.pth')\n",
    "        print(\"  🚀 Saved improved model\")\n",
    "\n",
    "print(\"Training complete. Best val loss:\", best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a25d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Config & Globals ---\n",
    "MODEL_PATH       = './best_path_energy_predictor.pth'\n",
    "DEVICE           = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "SCALING_METHOD   = 'log1p'  # since we used np.log1p in training\n",
    "\n",
    "# Assumes these exist in your namespace:\n",
    "#   graph        : torch_geometric.Data  (moved to DEVICE)\n",
    "#   G_nx         : networkx.Graph       (OSMnx graph_from_point)\n",
    "#   node_id_map  : dict[OSM ID → idx]\n",
    "#   val_loader   : DataLoader over validation set, collate_fn returning (paths_list, energy_log_tensor)\n",
    "#   val_trips_df : DataFrame (val_loader.dataset.trips) with columns ['source','destination','true_energy']\n",
    "\n",
    "# --- Load & prepare model ---\n",
    "# Bring your model class into scope\n",
    "# from your_pipeline_module import GNNPathEnergyPredictor\n",
    "\n",
    "node_dim = graph.x.shape[1]\n",
    "edge_dim = graph.edge_attr.shape[1]\n",
    "model = GNNPathEnergyPredictor(node_dim, edge_dim).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# --- Inverse scaling helper ---\n",
    "def inverse_scale(y_log):\n",
    "    y = y_log.cpu().numpy()\n",
    "    if SCALING_METHOD=='log1p':\n",
    "        return np.expm1(y)\n",
    "    return y\n",
    "\n",
    "# --- (A) General Performance on Val Set ---\n",
    "def analyze_general_performance(model, loader):\n",
    "    all_preds, all_actuals = [], []\n",
    "\n",
    "    for paths, energy_log in tqdm(loader, desc=\"Val preds\"):\n",
    "        # forward\n",
    "        preds_log = model(graph, [p.to(DEVICE) for p in paths])\n",
    "        # inverse-scale both preds & actuals\n",
    "        preds = inverse_scale(preds_log)\n",
    "        actuals = inverse_scale(energy_log)\n",
    "\n",
    "        all_preds.extend(preds)\n",
    "        all_actuals.extend(actuals)\n",
    "\n",
    "    y_pred = np.array(all_preds)\n",
    "    y_true = np.array(all_actuals)\n",
    "\n",
    "    # filter out any invalids\n",
    "    mask = np.isfinite(y_pred) & np.isfinite(y_true)\n",
    "    y_pred, y_true = y_pred[mask], y_true[mask]\n",
    "\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(\"\\nValidation Metrics (original scale):\")\n",
    "    print(f\"  MAE:  {mae:.3f}\")\n",
    "    print(f\"  RMSE: {rmse:.3f}\")\n",
    "    print(f\"  R²:   {r2:.3f}\")\n",
    "\n",
    "    # scatter\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.scatterplot(x=y_true, y=y_pred, alpha=0.5, s=10)\n",
    "    lims = [\n",
    "        np.min([y_true.min(), y_pred.min()])*0.9,\n",
    "        np.max([y_true.max(), y_pred.max()])*1.1\n",
    "    ]\n",
    "    plt.plot(lims, lims, '--', color='red', label='Ideal')\n",
    "    plt.xlabel(\"Actual Energy\")\n",
    "    plt.ylabel(\"Predicted Energy\")\n",
    "    plt.title(f\"Val: MAE={mae:.2f}, RMSE={rmse:.2f}, R²={r2:.2f}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlim(lims); plt.ylim(lims)\n",
    "    plt.show()\n",
    "\n",
    "# --- (B) Single-Route Visualization ---\n",
    "def plot_route_prediction(model, dataset_df, idx2osm, sample_idx):\n",
    "    # sample_idx is relative to val_trips_df.reset_index(drop=True)\n",
    "    row = dataset_df.iloc[sample_idx]\n",
    "    src, dst, E_true = row.source, row.destination, row.true_energy\n",
    "\n",
    "    # find NX shortest path on OSMnx graph\n",
    "    os_src = idx2osm[src]; os_dst = idx2osm[dst]\n",
    "    path_nodes = nx.shortest_path(G_nx, os_src, os_dst, weight='length')\n",
    "\n",
    "    # build edge-index list\n",
    "    # use same osm_edge_to_idx you built in pipeline\n",
    "    edge_list = []\n",
    "    for u,v in zip(path_nodes[:-1], path_nodes[1:]):\n",
    "        e = osm_edge_to_idx.get((u,v))\n",
    "        if e is not None:\n",
    "            edge_list.append(e)\n",
    "    edge_tensor = torch.tensor(edge_list, dtype=torch.long).to(DEVICE)\n",
    "\n",
    "    # predict\n",
    "    with torch.no_grad():\n",
    "        pred_log = model(graph, [edge_tensor])\n",
    "    E_pred = inverse_scale(pred_log).item()\n",
    "\n",
    "    print(f\"\\nRoute #{sample_idx}:  Actual={E_true:.1f}, Pred={E_pred:.1f}\")\n",
    "    # plot on map\n",
    "    fig, ax = ox.plot_graph_route(\n",
    "        G_nx, path_nodes,\n",
    "        route_color='r', route_linewidth=2, node_size=0,\n",
    "        show=False, close=False\n",
    "    )\n",
    "    ax.set_title(f\"Trip {sample_idx}: Pred={E_pred:.1f} vs Act={E_true:.1f}\")\n",
    "    plt.show()\n",
    "\n",
    "# --- (C) Weight Histograms ---\n",
    "def plot_weight_histograms(model, bins=50):\n",
    "    layers = {\n",
    "        'node_emb': model.node_emb,\n",
    "        'edge_emb': model.edge_emb,\n",
    "        'dec_L1':   model.decoder[0],\n",
    "        'dec_L2':   model.decoder[3],\n",
    "    }\n",
    "    n = len(layers)\n",
    "    fig, axes = plt.subplots((n+1)//2, 2, figsize=(10, 4*((n+1)//2)))\n",
    "    axes = axes.flatten()\n",
    "    for i,(name, layer) in enumerate(layers.items()):\n",
    "        w = layer.weight.data.cpu().numpy().ravel()\n",
    "        axes[i].hist(w, bins=bins)\n",
    "        axes[i].set_title(name)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Run everything ---\n",
    "if __name__ == \"__main__\":\n",
    "    # (1) General metrics + scatter\n",
    "    analyze_general_performance(model, val_loader)\n",
    "\n",
    "    # (2) Pick a random validation sample\n",
    "    val_trips_df = val_loader.dataset.trips\n",
    "    if len(val_trips_df):\n",
    "        idx2osm = {v:k for k,v in node_id_map.items()}\n",
    "        rnd = random.randrange(len(val_trips_df))\n",
    "        plot_route_prediction(model, val_trips_df, idx2osm, rnd)\n",
    "\n",
    "    # (3) Weight histograms\n",
    "    plot_weight_histograms(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
